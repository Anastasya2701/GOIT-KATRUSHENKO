{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPZPOUPbzzxFrn74jkL01Pj",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Anastasya2701/GOIT-KATRUSHENKO/blob/main/HW9.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "ttIAkzD5O39m"
      },
      "outputs": [],
      "source": [
        "import tensorflow as tf\n",
        "from tensorflow.keras.datasets import fashion_mnist\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout, Flatten, BatchNormalization, Input\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras.regularizers import l2"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "(x_train, y_train), (x_test, y_test) = fashion_mnist.load_data()\n",
        "x_train, x_test = x_train / 255.0, x_test / 255.0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ypBYiv2yQL1h",
        "outputId": "2886f902-6886-4ab6-974a-5b690dece289"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "\u001b[1m29515/29515\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "\u001b[1m26421880/26421880\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "\u001b[1m5148/5148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 1us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "\u001b[1m4422102/4422102\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Flatten(input_shape=(28, 28)),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dropout(0.3),\n",
        "    Dense(64, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    Dense(10, activation='softmax', kernel_regularizer=l2(0.001)),\n",
        "])"
      ],
      "metadata": {
        "id": "SzUALPmQQp2x"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "DjBis0oaS-4t"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=20, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ff-9eCVETo3e",
        "outputId": "cc61ecbc-62a6-4300-eac0-6635ff91e2b5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.5465 - loss: 1.9225 - val_accuracy: 0.7833 - val_loss: 1.1283\n",
            "Epoch 2/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.7901 - loss: 1.1246 - val_accuracy: 0.8253 - val_loss: 0.9660\n",
            "Epoch 3/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 11ms/step - accuracy: 0.8234 - loss: 0.9763 - val_accuracy: 0.8346 - val_loss: 0.8873\n",
            "Epoch 4/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 8ms/step - accuracy: 0.8375 - loss: 0.8876 - val_accuracy: 0.8432 - val_loss: 0.8255\n",
            "Epoch 5/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8473 - loss: 0.8225 - val_accuracy: 0.8538 - val_loss: 0.7734\n",
            "Epoch 6/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8540 - loss: 0.7705 - val_accuracy: 0.8564 - val_loss: 0.7341\n",
            "Epoch 7/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8564 - loss: 0.7323 - val_accuracy: 0.8578 - val_loss: 0.7039\n",
            "Epoch 8/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8627 - loss: 0.6957 - val_accuracy: 0.8584 - val_loss: 0.6793\n",
            "Epoch 9/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 8ms/step - accuracy: 0.8652 - loss: 0.6703 - val_accuracy: 0.8638 - val_loss: 0.6512\n",
            "Epoch 10/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8682 - loss: 0.6390 - val_accuracy: 0.8554 - val_loss: 0.6473\n",
            "Epoch 11/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 9ms/step - accuracy: 0.8662 - loss: 0.6278 - val_accuracy: 0.8642 - val_loss: 0.6180\n",
            "Epoch 12/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 8ms/step - accuracy: 0.8744 - loss: 0.5980 - val_accuracy: 0.8692 - val_loss: 0.5995\n",
            "Epoch 13/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 9ms/step - accuracy: 0.8752 - loss: 0.5836 - val_accuracy: 0.8707 - val_loss: 0.5836\n",
            "Epoch 14/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8755 - loss: 0.5678 - val_accuracy: 0.8665 - val_loss: 0.5782\n",
            "Epoch 15/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8773 - loss: 0.5572 - val_accuracy: 0.8689 - val_loss: 0.5664\n",
            "Epoch 16/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8803 - loss: 0.5411 - val_accuracy: 0.8710 - val_loss: 0.5543\n",
            "Epoch 17/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 9ms/step - accuracy: 0.8823 - loss: 0.5302 - val_accuracy: 0.8737 - val_loss: 0.5449\n",
            "Epoch 18/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 8ms/step - accuracy: 0.8847 - loss: 0.5156 - val_accuracy: 0.8729 - val_loss: 0.5400\n",
            "Epoch 19/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 11ms/step - accuracy: 0.8835 - loss: 0.5118 - val_accuracy: 0.8752 - val_loss: 0.5300\n",
            "Epoch 20/20\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 10ms/step - accuracy: 0.8835 - loss: 0.5090 - val_accuracy: 0.8752 - val_loss: 0.5196\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Точність на тестових даних: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rAHYqLTVU41e",
        "outputId": "87c7319b-77ad-452f-c1d6-42c551c53292"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.4149\n",
            "Точність на тестових даних: 88.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model = Sequential([\n",
        "    Input(shape=(28, 28)),\n",
        "    Flatten(),\n",
        "    Dense(512, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(256, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.4),\n",
        "    Dense(128, activation='relu', kernel_regularizer=l2(0.001)),\n",
        "    BatchNormalization(),\n",
        "    Dropout(0.3),\n",
        "    Dense(10, activation='softmax', kernel_regularizer=l2(0.001)),\n",
        "])"
      ],
      "metadata": {
        "id": "FFx3m54JWVzG"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.compile(optimizer=Adam(learning_rate=0.0001),\n",
        "              loss='sparse_categorical_crossentropy',\n",
        "              metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "XOxDWQLPXHrm"
      },
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "history = model.fit(x_train, y_train, epochs=25, batch_size=64, validation_data=(x_test, y_test))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6CHScWPXXMv6",
        "outputId": "3dce88e9-8b88-4daf-b01a-6ee3aaf6680f"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8851 - loss: 0.5277 - val_accuracy: 0.8851 - val_loss: 0.5290\n",
            "Epoch 2/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8885 - loss: 0.5085 - val_accuracy: 0.8849 - val_loss: 0.5209\n",
            "Epoch 3/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8884 - loss: 0.4962 - val_accuracy: 0.8774 - val_loss: 0.5218\n",
            "Epoch 4/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8957 - loss: 0.4675 - val_accuracy: 0.8782 - val_loss: 0.5079\n",
            "Epoch 5/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8934 - loss: 0.4640 - val_accuracy: 0.8829 - val_loss: 0.4974\n",
            "Epoch 6/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.8933 - loss: 0.4547 - val_accuracy: 0.8814 - val_loss: 0.4822\n",
            "Epoch 7/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8939 - loss: 0.4507 - val_accuracy: 0.8836 - val_loss: 0.4755\n",
            "Epoch 8/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8953 - loss: 0.4391 - val_accuracy: 0.8820 - val_loss: 0.4755\n",
            "Epoch 9/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.8950 - loss: 0.4324 - val_accuracy: 0.8849 - val_loss: 0.4636\n",
            "Epoch 10/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8947 - loss: 0.4306 - val_accuracy: 0.8857 - val_loss: 0.4569\n",
            "Epoch 11/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8978 - loss: 0.4123 - val_accuracy: 0.8858 - val_loss: 0.4565\n",
            "Epoch 12/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.8951 - loss: 0.4169 - val_accuracy: 0.8840 - val_loss: 0.4498\n",
            "Epoch 13/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 18ms/step - accuracy: 0.8980 - loss: 0.4023 - val_accuracy: 0.8865 - val_loss: 0.4350\n",
            "Epoch 14/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 18ms/step - accuracy: 0.8987 - loss: 0.3994 - val_accuracy: 0.8822 - val_loss: 0.4505\n",
            "Epoch 15/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.9001 - loss: 0.3934 - val_accuracy: 0.8850 - val_loss: 0.4351\n",
            "Epoch 16/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 17ms/step - accuracy: 0.8999 - loss: 0.3900 - val_accuracy: 0.8855 - val_loss: 0.4374\n",
            "Epoch 17/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 17ms/step - accuracy: 0.8995 - loss: 0.3835 - val_accuracy: 0.8892 - val_loss: 0.4294\n",
            "Epoch 18/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9025 - loss: 0.3771 - val_accuracy: 0.8884 - val_loss: 0.4241\n",
            "Epoch 19/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9004 - loss: 0.3800 - val_accuracy: 0.8827 - val_loss: 0.4320\n",
            "Epoch 20/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m20s\u001b[0m 18ms/step - accuracy: 0.9036 - loss: 0.3691 - val_accuracy: 0.8876 - val_loss: 0.4122\n",
            "Epoch 21/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9020 - loss: 0.3712 - val_accuracy: 0.8898 - val_loss: 0.4116\n",
            "Epoch 22/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 19ms/step - accuracy: 0.9013 - loss: 0.3681 - val_accuracy: 0.8922 - val_loss: 0.4044\n",
            "Epoch 23/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m19s\u001b[0m 17ms/step - accuracy: 0.9028 - loss: 0.3640 - val_accuracy: 0.8859 - val_loss: 0.4149\n",
            "Epoch 24/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m21s\u001b[0m 18ms/step - accuracy: 0.9037 - loss: 0.3605 - val_accuracy: 0.8879 - val_loss: 0.4138\n",
            "Epoch 25/25\n",
            "\u001b[1m938/938\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 17ms/step - accuracy: 0.9013 - loss: 0.3653 - val_accuracy: 0.8896 - val_loss: 0.4107\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test_loss, test_accuracy = model.evaluate(x_test, y_test)\n",
        "print(f'Точність на тестових даних: {test_accuracy * 100:.2f}%')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wmEc2m4jXPTQ",
        "outputId": "87000d08-2082-4041-e0a0-d5237fe43b49"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m313/313\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 4ms/step - accuracy: 0.8917 - loss: 0.4149\n",
            "Точність на тестових даних: 88.96%\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Висновок\n",
        "\n",
        "У ході виконання завдання було побудовано нейронну мережу для класифікації зображень із датасету fashion_mnist. Основними завданнями було досягти точності не нижче 91% та експериментувати з гіперпараметрами для оптимізації результатів.\n",
        "\n",
        "Основні етапи роботи:\n",
        "\n",
        " 1. Архітектура нейронної мережі: було створено багатошарову мережу, використавши кілька щільних (Dense) шарів із функцією активації ReLU. Також були додані регуляризації L2 та Dropout для запобігання перенавчанню.\n",
        " 2. Оптимізація: Використано оптимізатор Adam з малим коефіцієнтом навчання (learning rate = 0.0001), щоб стабілізувати навчання і поліпшити результати.\n",
        " 3. Налаштування гіперпараметрів: Експериментували з кількістю нейронів, кількістю епох, розміром батчу.\n",
        " 4. Додано нормалізацію шарів (BatchNormalization): Це допомогло стабілізувати процес навчання і зробити модель більш стійкою до зміни значень вхідних даних.\n",
        " 5. Збільшено кількість шарів і нейронів: Збільшино кількість нейронів у кожному шарі для підвищення здатності моделі до розпізнавання складних шаблонів.\n",
        " 6. Розширена регуляризація: Було додано Dropout із більшим коефіцієнтом (0.4 для перших шарів), що зменшило ризик перенавчання моделі.\n",
        "\n",
        "Результати:\n",
        "\n",
        "Після тренування модель показала певний рівень точності на тестовій вибірці. На жаль точність не дійшла до потрібного рівня в 91%. Думаю якщо ще поексперемнтувати з гіперпараментрами то можна дійти до необхідного % точності.\n",
        "\n",
        "\n",
        "У цілому, виконане завдання дозволило краще зрозуміти принципи роботи з нейронними мережами в Keras, налаштування гіперпараметрів та застосування різних технік регуляризації для покращення узагальнюючої здатності моделі."
      ],
      "metadata": {
        "id": "4AiJJE7vZmJB"
      }
    }
  ]
}